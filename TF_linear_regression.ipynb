{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤分析：\n",
    "#1.构建数据集：假设为 y = 2.5*x + 2，共100个样本\n",
    "#2.建立线性模型，Y = wX + b，求出w和b\n",
    "#3.使用平方损失函数作为loss ：loss = (Y - y)**2\n",
    "#4.利用梯度下降优化算法优化损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random_normal(shape=[100, 1], name = 'x', seed = 6)\n",
    "y = tf.matmul(x,[[2.5]]) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机初始化w和b\n",
    "#w = tf.Variable(initial_value=tf.random_normal(shape=[1]),name='w')\n",
    "#b = tf.Variable(initial_value=tf.random_normal(shape=[1]), name='b')\n",
    "w = tf.Variable(initial_value=tf.random_uniform(shape=[1], minval=-1.0, maxval=1.0), name='w')\n",
    "b = tf.Variable(initial_value=tf.zeros([1]), name='b')\n",
    "#建立模型\n",
    "Y = w*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立损失函数\n",
    "loss = tf.reduce_mean(tf.square(Y - y),name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#梯度下降法优化\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01,name='SGD').minimize(loss,name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w [-0.6375346]\n",
      "b [0.]\n",
      "loss 12.756958\n",
      "w = [-0.59061366], b = [0.03474636], loss = 13.891807556152344\n",
      "w = [-0.53313994], b = [0.07664786], loss = 9.865205764770508\n",
      "w = [-0.46992245], b = [0.12063937], loss = 11.905426025390625\n",
      "w = [-0.3859663], b = [0.15527222], loss = 14.034420013427734\n",
      "w = [-0.33838484], b = [0.18915856], loss = 10.658559799194336\n",
      "w = [-0.2917997], b = [0.22901289], loss = 11.121878623962402\n",
      "w = [-0.24460363], b = [0.271384], loss = 10.2864408493042\n",
      "w = [-0.19011855], b = [0.2977504], loss = 10.492304801940918\n",
      "w = [-0.13175416], b = [0.33552492], loss = 8.716286659240723\n",
      "w = [-0.07497019], b = [0.37231383], loss = 8.250924110412598\n",
      "w = [-0.02029108], b = [0.39989004], loss = 11.097434043884277\n",
      "w = [0.02600378], b = [0.43141076], loss = 10.136236190795898\n",
      "w = [0.0834258], b = [0.47322083], loss = 10.105485916137695\n",
      "w = [0.12950057], b = [0.5035801], loss = 7.446580410003662\n",
      "w = [0.17235488], b = [0.53189105], loss = 5.912271022796631\n",
      "w = [0.21081941], b = [0.5564627], loss = 7.504777908325195\n",
      "w = [0.25779456], b = [0.58600396], loss = 5.534185409545898\n",
      "w = [0.29844317], b = [0.61373466], loss = 7.279196262359619\n",
      "w = [0.34049523], b = [0.6395287], loss = 6.003091812133789\n",
      "w = [0.38465962], b = [0.67163306], loss = 4.754228591918945\n",
      "w = [0.4279617], b = [0.6973905], loss = 4.888684272766113\n",
      "w = [0.47134343], b = [0.7293099], loss = 5.950352191925049\n",
      "w = [0.51320595], b = [0.7627012], loss = 5.673725128173828\n",
      "w = [0.55701333], b = [0.78982544], loss = 5.039269924163818\n",
      "w = [0.59105265], b = [0.81017715], loss = 5.2787275314331055\n",
      "w = [0.63253444], b = [0.83688116], loss = 4.710388660430908\n",
      "w = [0.6784084], b = [0.86287653], loss = 4.919904708862305\n",
      "w = [0.7103678], b = [0.88332987], loss = 4.311283588409424\n",
      "w = [0.74169225], b = [0.9150544], loss = 4.52615213394165\n",
      "w = [0.7744618], b = [0.9412447], loss = 3.7905895709991455\n",
      "w = [0.8082919], b = [0.9509453], loss = 3.5806057453155518\n",
      "w = [0.84682333], b = [0.973812], loss = 3.6780805587768555\n",
      "w = [0.880978], b = [0.9929705], loss = 5.058564186096191\n",
      "w = [0.9100179], b = [1.0155385], loss = 3.178727626800537\n",
      "w = [0.93850815], b = [1.0313534], loss = 2.843893527984619\n",
      "w = [0.96960974], b = [1.0536065], loss = 3.0413870811462402\n",
      "w = [0.9989476], b = [1.0701771], loss = 2.8051464557647705\n",
      "w = [1.0170741], b = [1.0891689], loss = 2.2644684314727783\n",
      "w = [1.0501684], b = [1.1089948], loss = 3.0091912746429443\n",
      "w = [1.0836616], b = [1.1259015], loss = 2.9965548515319824\n",
      "w = [1.1178886], b = [1.1476706], loss = 1.9274767637252808\n",
      "w = [1.1448116], b = [1.1639661], loss = 2.271270751953125\n",
      "w = [1.1674135], b = [1.1825136], loss = 2.689589023590088\n",
      "w = [1.1984938], b = [1.1992863], loss = 1.7626996040344238\n",
      "w = [1.2205993], b = [1.2150235], loss = 3.0785467624664307\n",
      "w = [1.2457829], b = [1.2316747], loss = 1.7302778959274292\n",
      "w = [1.2731504], b = [1.2450279], loss = 2.1384243965148926\n",
      "w = [1.3003204], b = [1.2657129], loss = 1.7325448989868164\n",
      "w = [1.3249564], b = [1.2795548], loss = 1.8045545816421509\n",
      "w = [1.3470787], b = [1.2971115], loss = 2.2000603675842285\n",
      "w = [1.36808], b = [1.3092573], loss = 1.645288109779358\n",
      "w = [1.3884658], b = [1.3216398], loss = 2.143479824066162\n",
      "w = [1.4132715], b = [1.3366994], loss = 1.6305031776428223\n",
      "w = [1.4320651], b = [1.3501742], loss = 1.3769804239273071\n",
      "w = [1.4504473], b = [1.3633026], loss = 1.3594613075256348\n",
      "w = [1.4658424], b = [1.3741004], loss = 1.3983198404312134\n",
      "w = [1.4867347], b = [1.3804744], loss = 1.3578990697860718\n",
      "w = [1.5078635], b = [1.3902123], loss = 1.8735095262527466\n",
      "w = [1.5260684], b = [1.404265], loss = 1.1547678709030151\n",
      "w = [1.5483015], b = [1.4152318], loss = 1.0701709985733032\n",
      "w = [1.5699569], b = [1.4306595], loss = 1.169031023979187\n",
      "w = [1.5902524], b = [1.4406954], loss = 1.382715106010437\n",
      "w = [1.6083238], b = [1.4512153], loss = 1.2315714359283447\n",
      "w = [1.6292799], b = [1.4612081], loss = 1.0575613975524902\n",
      "w = [1.6482983], b = [1.471239], loss = 1.00465726852417\n",
      "w = [1.6677623], b = [1.4850013], loss = 1.0977994203567505\n",
      "w = [1.6830266], b = [1.4985394], loss = 1.2380092144012451\n",
      "w = [1.702788], b = [1.5113925], loss = 0.8259829878807068\n",
      "w = [1.7213879], b = [1.5199214], loss = 0.7506825923919678\n",
      "w = [1.7377073], b = [1.5296459], loss = 0.8977998495101929\n",
      "w = [1.7518924], b = [1.5392573], loss = 0.7922854423522949\n",
      "w = [1.7686542], b = [1.5458231], loss = 0.837022066116333\n",
      "w = [1.7820684], b = [1.5530132], loss = 0.7412480115890503\n",
      "w = [1.7949218], b = [1.5619495], loss = 0.6205295324325562\n",
      "w = [1.8071538], b = [1.5700734], loss = 0.7846075296401978\n",
      "w = [1.8269184], b = [1.582528], loss = 0.5511116981506348\n",
      "w = [1.8426056], b = [1.5892496], loss = 0.6779604554176331\n",
      "w = [1.852558], b = [1.5969445], loss = 0.7522091865539551\n",
      "w = [1.8608158], b = [1.6045904], loss = 0.652498722076416\n",
      "w = [1.8735218], b = [1.6110091], loss = 0.6180130243301392\n",
      "w = [1.8870573], b = [1.618735], loss = 0.5360656976699829\n",
      "w = [1.89843], b = [1.626385], loss = 0.4866844117641449\n",
      "w = [1.9123427], b = [1.6338301], loss = 0.5371354222297668\n",
      "w = [1.92711], b = [1.6412864], loss = 0.47686266899108887\n",
      "w = [1.9368463], b = [1.6486654], loss = 0.4402081370353699\n",
      "w = [1.9477923], b = [1.6563764], loss = 0.2932770252227783\n",
      "w = [1.9572486], b = [1.662604], loss = 0.33100348711013794\n",
      "w = [1.9666951], b = [1.667711], loss = 0.46432921290397644\n",
      "w = [1.9748591], b = [1.6744511], loss = 0.2948748469352722\n",
      "w = [1.9863851], b = [1.6816192], loss = 0.32383111119270325\n",
      "w = [1.9966295], b = [1.6891543], loss = 0.3600897490978241\n",
      "w = [2.0095413], b = [1.6954441], loss = 0.321578711271286\n",
      "w = [2.0241203], b = [1.7007941], loss = 0.2948255240917206\n",
      "w = [2.035306], b = [1.7072561], loss = 0.2432776242494583\n",
      "w = [2.0445828], b = [1.7137206], loss = 0.36373192071914673\n",
      "w = [2.052266], b = [1.7194064], loss = 0.2677036225795746\n",
      "w = [2.0595152], b = [1.7253006], loss = 0.2685508728027344\n",
      "w = [2.067666], b = [1.7306583], loss = 0.2478533238172531\n",
      "w = [2.0754187], b = [1.7356579], loss = 0.23437181115150452\n",
      "w = [2.0847967], b = [1.7409031], loss = 0.25731638073921204\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #初始化\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('w', sess.run(w))\n",
    "    print('b', sess.run(b))\n",
    "    print('loss', sess.run(loss))\n",
    "    for i in range(100):\n",
    "        #模型训练\n",
    "        sess.run(train)\n",
    "        print('w = {}, b = {}, loss = {}'.format(sess.run(w), sess.run(b), sess.run(loss)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
