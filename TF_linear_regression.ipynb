{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤分析：\n",
    "#1.构建数据集：假设为 y = 2.5*x + 2，共100个样本\n",
    "#2.建立线性模型，Y = wX + b，求出w和b\n",
    "#3.使用平方损失函数作为loss ：loss = (Y - y)**2\n",
    "#4.利用梯度下降优化算法优化损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random_normal(shape=[100, 1], name = 'x', seed = 6)\n",
    "y = tf.matmul(x,[[2.5]]) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机初始化w和b\n",
    "#w = tf.Variable(initial_value=tf.random_normal(shape=[1]),name='w')\n",
    "#b = tf.Variable(initial_value=tf.random_normal(shape=[1]), name='b')\n",
    "#建立模型\n",
    "Y = w*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立损失函数\n",
    "loss = tf.reduce_mean(tf.square(Y - y),name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#梯度下降法优化\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01,name='SGD').minimize(loss,name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w [0.3234017]\n",
      "b [0.]\n",
      "loss 7.906636\n",
      "w = [0.35492644], b = [0.0363554], loss = 8.75592041015625\n",
      "w = [0.39532045], b = [0.07743036], loss = 6.354138374328613\n",
      "w = [0.44025764], b = [0.11971515], loss = 7.690600395202637\n",
      "w = [0.49791023], b = [0.1552719], loss = 8.689327239990234\n",
      "w = [0.5303301], b = [0.19007957], loss = 6.736076831817627\n",
      "w = [0.56336653], b = [0.22880219], loss = 7.084812641143799\n",
      "w = [0.59745705], b = [0.2690482], loss = 6.380580902099609\n",
      "w = [0.63363314], b = [0.29797897], loss = 6.651835918426514\n",
      "w = [0.6748479], b = [0.33460686], loss = 5.530564785003662\n",
      "w = [0.7149078], b = [0.3703416], loss = 5.227838516235352\n",
      "w = [0.751845], b = [0.39948413], loss = 6.784755706787109\n",
      "w = [0.7838629], b = [0.43116048], loss = 6.392951011657715\n",
      "w = [0.82572323], b = [0.469778], loss = 6.222049713134766\n",
      "w = [0.85761076], b = [0.5002603], loss = 4.652650356292725\n",
      "w = [0.88698626], b = [0.52913445], loss = 3.7683327198028564\n",
      "w = [0.9127081], b = [0.55523205], loss = 4.617650032043457\n",
      "w = [0.94541013], b = [0.58459234], loss = 3.542234182357788\n",
      "w = [0.9734865], b = [0.61251974], loss = 4.486659526824951\n",
      "w = [1.0022706], b = [0.63893026], loss = 3.9481594562530518\n",
      "w = [1.0338473], b = [0.66954654], loss = 3.09859561920166\n",
      "w = [1.0637033], b = [0.69559425], loss = 3.0834524631500244\n",
      "w = [1.0949115], b = [0.72574943], loss = 3.7427573204040527\n",
      "w = [1.1254562], b = [0.7567598], loss = 3.5716052055358887\n",
      "w = [1.1562275], b = [0.78327], loss = 3.328850746154785\n",
      "w = [1.1790162], b = [0.8049407], loss = 3.342242956161499\n",
      "w = [1.2082876], b = [0.83085394], loss = 2.956282377243042\n",
      "w = [1.2405518], b = [0.85612726], loss = 3.0815606117248535\n",
      "w = [1.262199], b = [0.87742203], loss = 2.668693780899048\n",
      "w = [1.2857025], b = [0.906369], loss = 2.882302761077881\n",
      "w = [1.3092129], b = [0.9313434], loss = 2.418178081512451\n",
      "w = [1.3303112], b = [0.944798], loss = 2.2812600135803223\n",
      "w = [1.3573204], b = [0.96720576], loss = 2.2671945095062256\n",
      "w = [1.380661], b = [0.986918], loss = 3.1233932971954346\n",
      "w = [1.4012133], b = [1.0088578], loss = 1.955803394317627\n",
      "w = [1.4201447], b = [1.0260032], loss = 1.775428295135498\n",
      "w = [1.442214], b = [1.047475], loss = 1.8927626609802246\n",
      "w = [1.4620323], b = [1.0648961], loss = 1.7534658908843994\n",
      "w = [1.4746436], b = [1.0838716], loss = 1.405714511871338\n",
      "w = [1.4978371], b = [1.1033069], loss = 1.894297480583191\n",
      "w = [1.5208116], b = [1.1206093], loss = 1.8524842262268066\n",
      "w = [1.5453072], b = [1.1411611], loss = 1.2009731531143188\n",
      "w = [1.5637574], b = [1.157819], loss = 1.4643248319625854\n",
      "w = [1.5797287], b = [1.1759248], loss = 1.6602087020874023\n",
      "w = [1.601275], b = [1.1926985], loss = 1.0981413125991821\n",
      "w = [1.6164852], b = [1.2086531], loss = 1.9260509014129639\n",
      "w = [1.6340616], b = [1.2251371], loss = 1.1026583909988403\n",
      "w = [1.6525645], b = [1.2392443], loss = 1.3209360837936401\n",
      "w = [1.6724212], b = [1.2583176], loss = 1.1296499967575073\n",
      "w = [1.6892506], b = [1.2725692], loss = 1.1705527305603027\n",
      "w = [1.7051314], b = [1.2892897], loss = 1.338597059249878\n",
      "w = [1.7192355], b = [1.3021857], loss = 1.0049388408660889\n",
      "w = [1.7330168], b = [1.315154], loss = 1.3328334093093872\n",
      "w = [1.7504245], b = [1.3298807], loss = 1.03145170211792\n",
      "w = [1.7634283], b = [1.3434272], loss = 0.898907482624054\n",
      "w = [1.7761326], b = [1.3566496], loss = 0.8439834713935852\n",
      "w = [1.7863736], b = [1.3681813], loss = 0.862446129322052\n",
      "w = [1.7996029], b = [1.3765781], loss = 0.8318449258804321\n",
      "w = [1.8136966], b = [1.3872129], loss = 1.1522479057312012\n",
      "w = [1.8266473], b = [1.4007531], loss = 0.7455428838729858\n",
      "w = [1.8418362], b = [1.4120827], loss = 0.6993091702461243\n",
      "w = [1.857532], b = [1.4264221], loss = 0.729227602481842\n",
      "w = [1.8712902], b = [1.4369605], loss = 0.8698041439056396\n",
      "w = [1.8836497], b = [1.4477608], loss = 0.7803322076797485\n",
      "w = [1.8979445], b = [1.4581262], loss = 0.6360141038894653\n",
      "w = [1.9109498], b = [1.4684485], loss = 0.6412263512611389\n",
      "w = [1.925032], b = [1.4812839], loss = 0.6797155141830444\n",
      "w = [1.9362115], b = [1.4938953], loss = 0.7513990998268127\n",
      "w = [1.9504019], b = [1.5059661], loss = 0.5266804695129395\n",
      "w = [1.9629796], b = [1.5149897], loss = 0.47082069516181946\n",
      "w = [1.9742596], b = [1.5247747], loss = 0.5677556991577148\n",
      "w = [1.9840833], b = [1.5344201], loss = 0.4977301061153412\n",
      "w = [1.9951192], b = [1.5419049], loss = 0.5052326917648315\n",
      "w = [2.0040054], b = [1.5497597], loss = 0.46991798281669617\n",
      "w = [2.0128846], b = [1.5587622], loss = 0.40159717202186584\n",
      "w = [2.0212102], b = [1.5671468], loss = 0.48845359683036804\n",
      "w = [2.035624], b = [1.5784686], loss = 0.3545736074447632\n",
      "w = [2.0461242], b = [1.5857761], loss = 0.4369747042655945\n",
      "w = [2.0528922], b = [1.5937015], loss = 0.4663817286491394\n",
      "w = [2.0585127], b = [1.6015408], loss = 0.40959441661834717\n",
      "w = [2.0669968], b = [1.6084812], loss = 0.3801829218864441\n",
      "w = [2.0763416], b = [1.6162742], loss = 0.3266479969024658\n",
      "w = [2.084207], b = [1.6239659], loss = 0.31557127833366394\n",
      "w = [2.093818], b = [1.6314677], loss = 0.32958588004112244\n",
      "w = [2.104051], b = [1.6389302], loss = 0.30510884523391724\n",
      "w = [2.1108208], b = [1.6462932], loss = 0.2772490680217743\n",
      "w = [2.11852], b = [1.6538402], loss = 0.18614709377288818\n",
      "w = [2.1249256], b = [1.6603179], loss = 0.22112149000167847\n",
      "w = [2.1311316], b = [1.6659776], loss = 0.28664278984069824\n",
      "w = [2.136797], b = [1.6727233], loss = 0.1908913552761078\n",
      "w = [2.1448965], b = [1.6797233], loss = 0.19958452880382538\n",
      "w = [2.152207], b = [1.6869359], loss = 0.22642654180526733\n",
      "w = [2.1611423], b = [1.6932476], loss = 0.20073610544204712\n",
      "w = [2.1710694], b = [1.6988705], loss = 0.19046737253665924\n",
      "w = [2.1788957], b = [1.7052234], loss = 0.16075830161571503\n",
      "w = [2.1854274], b = [1.7115402], loss = 0.22829589247703552\n",
      "w = [2.1907263], b = [1.7172819], loss = 0.16732215881347656\n",
      "w = [2.1957898], b = [1.7231313], loss = 0.1675991266965866\n",
      "w = [2.201392], b = [1.7285746], loss = 0.15800215303897858\n",
      "w = [2.2066703], b = [1.7337357], loss = 0.1521948277950287\n",
      "w = [2.213141], b = [1.7390323], loss = 0.16290542483329773\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #初始化\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('w', sess.run(w))\n",
    "    print('b', sess.run(b))\n",
    "    print('loss', sess.run(loss))\n",
    "    for i in range(100):\n",
    "        #模型训练\n",
    "        sess.run(train)\n",
    "        print('w = {}, b = {}, loss = {}'.format(sess.run(w), sess.run(b), sess.run(loss)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
